# -*- coding: utf-8 -*-
"""Drone Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14bG70UwY15Gx1mXOQ7kTxFuQP983nx50
"""

# https://towardsdatascience.com/count-number-of-cars-in-less-than-10-lines-of-code-using-python-40208b173554
from google.colab import drive
drive.mount('/content/drive')

import cv2
import time
import numpy as np
import cv2
import time
import numpy as np
import matplotlib.pyplot as plt
# from google.colab.patches import cv2_imshow

def imshow(inp, title=None):
    """Imshow for Tensor."""
    #inp = inp.numpy().transpose((1, 2, 0))
    #mean = np.array([0.485, 0.456, 0.406])
    #std = np.array([0.229, 0.224, 0.225])
    #inp = std * inp + mean
    #inp = np.clip(inp, 0, 1)
    if title is not None:
        plt.title(title)

    if inp is not None:
      plt.imshow(inp)
      plt.pause(0.000000001)  # pause a bit so that plots are updated

    else:
      pass
 
def centre_handle(x,y,w,h):
  x1=(int)(w/2)
  y1=(int)(h/2)
  cx=x+x1
  cy=y+y1
  return cx,cy
offset=5
detect=[]
counter=0

img=[]
# initialize subtractor
algo=cv2.createBackgroundSubtractorMOG2()
count_line_position=300
min_height_rect=240
min_width_rect=110


res = cv2.VideoWriter_fourcc(*'mp4v') 
video = cv2.VideoWriter('video.mp4', res, 1, (2000, 1200))


cap=cv2.VideoCapture('/content/drive/MyDrive/Drone Competition /DRONE-SURVEILLANCE-CONTEST-VIDEO.mp4')
video_length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - 1
i=0
while True:
    
    i+=1

    if i > 2000:
      break

    ret,frame1 = cap.read()
    if frame1 is not None:
      grey = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)
      blur = cv2.GaussianBlur(grey,(3,3),5)
      img_sub = algo.apply(blur)
      dilat = cv2.dilate(img_sub,np.ones((5,5)))
      kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))
      dilatada = cv2.morphologyEx(dilat,cv2.MORPH_CLOSE,kernel)
      dilatada = cv2.morphologyEx(dilatada,cv2.MORPH_CLOSE,kernel)
      counterShape,h = cv2.findContours(dilatada,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)
      cv2.line(frame1,(0,300),(2000,300),(255,127,0),10)
      for (i,c) in enumerate(counterShape):
        (x,y,w,h)=cv2.boundingRect(c)
        validateCounter = (w>=min_width_rect) and (h>min_height_rect)
        if not validateCounter:
          continue
        cv2.rectangle(frame1,(x,y),(x+w,y+h),(0,255,0),5)
    
        centre=centre_handle(x,y,w,h)
        detect.append(centre)
        cv2.circle(frame1,centre,10,(255,0,0),-1)

        for (x,y) in detect:
          if y<(count_line_position+offset) and (y>count_line_position-offset):
            counter+=1
          cv2.line(frame1,(0,300),(2000,300),(0,127,255),10)
          detect.remove((x,y))

    cv2.putText(frame1," "+str(counter),(1700,100),cv2.FONT_HERSHEY_COMPLEX,2,(0,0,255),10)
    cv2.putText(frame1,"RATI KUMARI",(850,100),cv2.FONT_HERSHEY_COMPLEX,2,(0,0,255),8)
    if frame1 is not None:
      imshow(frame1)

    video.write(frame1)
    
    
cap.release()
cv2.destroyAllWindows()

#